<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR 眼镜换戴</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
    #ar-button {
      position: absolute;
      top: 20px;
      left: 20px;
      padding: 10px;
      background: rgba(0, 0, 0, 0.6);
      color: white;
      font-size: 18px;
      border-radius: 8px;
      z-index: 10;
    }
    #switch-button {
      position: absolute;
      top: 100px;
      left: 20px;
      padding: 10px;
      background: rgba(0, 0, 0, 0.6);
      color: white;
      font-size: 18px;
      border-radius: 8px;
      z-index: 10;
    }
  </style>
</head>
<body>
  <button id="ar-button">启动 AR</button>
  <button id="switch-button" style="display: none;">切换眼镜</button>

  <!-- 引入 Three.js -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.137.5/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.137.5/examples/js/controls/OrbitControls.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.137.5/examples/js/loaders/GLTFLoader.js"></script>

  <!-- 引入 face-api.js -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

  <script>
    let scene, camera, renderer, video, videoTexture, model1, model2, currentModel;
    const arButton = document.getElementById('ar-button');
    const switchButton = document.getElementById('switch-button');
    const loader = new THREE.GLTFLoader();
    let videoStream = null;

    // 初始化Three.js场景
    function initThreeJS() {
      scene = new THREE.Scene();
      camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
      renderer = new THREE.WebGLRenderer({ alpha: true });
      renderer.setSize(window.innerWidth, window.innerHeight);
      document.body.appendChild(renderer.domElement);

      // 初始化视频作为背景
      initVideoBackground();

      // 加载第一个眼镜模型
      loadGlassesModel('glasses.glb', (model) => {
        model1 = model;
        model1.position.set(0, -0.5, -2); // 调整眼镜模型位置
        model1.scale.set(2, 2, 2);  // 调整眼镜模型大小
        scene.add(model1);
        currentModel = model1; // 默认眼镜
      });

      // 加载第二个眼镜模型
      loadGlassesModel('glasses.glb', (model) => {
        model2 = model;
        model2.position.set(0, -0.5, -2); // 调整眼镜模型位置
        model2.scale.set(0.5, 0.5, 0.5);  // 调整眼镜模型大小
        model2.visible = false; // 默认隐藏
        scene.add(model2);
      });

      // 添加OrbitControls来查看模型
      const controls = new THREE.OrbitControls(camera, renderer.domElement);
      camera.position.z = 3; // 确保相机远离模型
    }

    // 初始化视频背景（使用摄像头视频流）
    function initVideoBackground() {
      video = document.createElement('video');
      video.width = window.innerWidth;
      video.height = window.innerHeight;
      video.autoplay = true;
      video.muted = true;
      video.playsInline = true;

      // 获取摄像头视频流
      navigator.mediaDevices.getUserMedia({ video: true })
        .then((stream) => {
          video.srcObject = stream;
          video.play();

          // 将摄像头流作为视频纹理
          videoTexture = new THREE.VideoTexture(video);
          videoTexture.minFilter = THREE.LinearFilter;
          videoTexture.magFilter = THREE.LinearFilter;
          videoTexture.format = THREE.RGBFormat;

          // 创建背景视频平面
          const videoGeometry = new THREE.PlaneGeometry(16, 9);
          const videoMaterial = new THREE.MeshBasicMaterial({ map: videoTexture });
          const videoPlane = new THREE.Mesh(videoGeometry, videoMaterial);
          scene.add(videoPlane);

          // 设置视频的位置
          videoPlane.position.z = -5;
        })
        .catch((err) => {
          console.error('无法访问摄像头:', err);
        });
    }

    // 加载眼镜模型
    function loadGlassesModel(modelPath, callback) {
      loader.load(modelPath, (gltf) => {
        const model = gltf.scene;
        console.log(`加载模型：${modelPath}`);
        callback(model);
      }, undefined, (error) => {
        console.error('加载眼镜模型失败', error);
      });
    }

    // 启动摄像头
    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        video.play();
      } catch (err) {
        console.error('无法访问摄像头：', err);
      }
    }

    // 切换眼镜
    function switchGlasses() {
      if (currentModel === model1) {
        console.log("model2！");
        model1.visible = false;
        model2.visible = true;
        currentModel = model2;
      } else {
        console.log("model1！");
        model2.visible = false;
        model1.visible = true;
        currentModel = model1;
      }
    }

    // 渲染每一帧
    function animate() {
      requestAnimationFrame(animate);
      renderer.render(scene, camera);
    }

    // 启动AR按钮点击事件
    arButton.addEventListener('click', () => {
      startCamera(); // 启动摄像头
      arButton.style.display = 'none'; // 隐藏按钮
      switchButton.style.display = 'block'; // 显示切换眼镜按钮
      initThreeJS(); // 初始化Three.js
      animate(); // 开始渲染动画
    });

    // 切换眼镜按钮点击事件
    switchButton.addEventListener('click', () => {
      switchGlasses();
    });


    // 初始化面部识别
    window.onload = async function () {
      try {
        // 加载模型文件
      await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
      await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
      
      const videoElement = document.createElement('video');
      document.body.append(videoElement);
      
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      videoElement.srcObject = stream;
      videoElement.play();

      videoElement.onplay = () => {
        setInterval(async () => {
          const detections = await faceapi.detectAllFaces(videoElement).withFaceLandmarks();
          if (detections.length > 0) {
            const landmarks = detections[0].landmarks;
            const leftEye = landmarks.getLeftEye();
            const rightEye = landmarks.getRightEye();

            // 计算眼睛之间的距离等，调整眼镜模型的位置
            model1.position.set(
              (leftEye[3].x + rightEye[3].x) / 2, 
              (leftEye[3].y + rightEye[3].y) / 2, 
              -2
            );
          }
        }, 100);
      };
        
        console.log("模型加载完成！");
        
        // 继续执行你需要的其他逻辑
        // 比如打开视频流并做面部检测等
      } catch (err) {
        console.error("加载模型时出错", err);
      }
    }
  </script>
</body>
</html>
