<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>虚拟眼镜放在WebCam眼睛上</title>
    <style>
        body { margin: 0; overflow: hidden; }
        canvas { display: block; }
    </style>
</head>
<body>
    <!-- 引入 Three.js, GLTFLoader, Face-api.js -->
    <script src="https://cdn.jsdelivr.net/npm/three@0.132.2/build/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.132.2/examples/js/loaders/GLTFLoader.js"></script>
    <script src="face-api.js"></script>

    <script>
        let scene, camera, renderer;
        let glassesModel;
        let videoCanvas, videoContext;
        let lastDetectionTime = 0;
        const detectionInterval = 200;  // 面部检测的时间间隔 (200ms)
        const FPS = 60;  // 设置帧率为60
        const frameDuration = 1000 / FPS;  // 每帧的持续时间（毫秒）

        // 初始化Three.js
        function init() {
            // 初始化场景、相机和渲染器
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            // 添加光源
            var light = new THREE.PointLight(0xffffff, 1, 100);
            light.position.set(10, 10, 10);
            scene.add(light);

            // 加载虚拟眼镜模型
            var loader = new THREE.GLTFLoader();
            loader.load('glasses.glb', function (gltf) {
                glassesModel = gltf.scene;
                glassesModel.scale.set(1.1, 1.1, 1.1);  // 调整模型大小
                scene.add(glassesModel);
            });

            // 设置相机位置
            camera.position.set(0, 1, 5);

            // 创建canvas用于显示WebCam视频
            videoCanvas = document.createElement('canvas');
            videoCanvas.width = window.innerWidth;
            videoCanvas.height = window.innerHeight;
            videoContext = videoCanvas.getContext('2d', { willReadFrequently: true });
            document.body.appendChild(videoCanvas);

            // 获取WebCam视频流
            navigator.mediaDevices.getUserMedia({
                video: { width: 640, height: 480 }  // 降低WebCam分辨率以提高性能
            })
            .then(function (stream) {
                var video = document.createElement('video');
                video.srcObject = stream;
                video.play();

                video.onloadeddata = function () {
                    function drawVideo() {
                        videoContext.drawImage(video, 0, 0, videoCanvas.width, videoCanvas.height);
                        requestAnimationFrame(drawVideo);
                    }
                    drawVideo();
                };
            })
            .catch(function (err) {
                console.error('WebCam 错误: ' + err);
            });

            // 加载face-api.js模型
            loadFaceApi();

            // 启动渲染循环
            animate();
        }

        // 加载face-api.js模型
        async function loadFaceApi() {
            try {
                // 确保模型加载完成
                await faceapi.nets.ssdMobilenetv1.load('/'); // 加载面部检测模型
                await faceapi.nets.faceLandmark68Net.load('/'); // 加载面部标志点模型
                await faceapi.nets.faceRecognitionNet.load('/'); // 加载人脸识别模型

                // 确保模型加载完成后再开始面部检测
                detectFace();
            } catch (error) {
                console.error('模型加载失败: ', error);
            }
        }

        // 面部检测
        async function detectFace() {
            const currentTime = performance.now();
            if (currentTime - lastDetectionTime >= detectionInterval) {
                const detections = await faceapi.detectAllFaces(videoCanvas).withFaceLandmarks();
                if (detections.length > 0) {
                    const landmarks = detections[0].landmarks;
                    const leftEye = landmarks.getLeftEye();
                    const rightEye = landmarks.getRightEye();

                    // 计算眼睛的中心点
                    const eyeCenterX = (leftEye[3].x + rightEye[3].x) / 2;
                    const eyeCenterY = (leftEye[3].y + rightEye[3].y) / 2;

                    // 将眼睛中心位置映射到3D空间
                    if (glassesModel) {
                        glassesModel.position.set(
                            eyeCenterX / window.innerWidth * 2 - 1,  // 横坐标映射
                            eyeCenterY / window.innerHeight * -2 + 1, // 纵坐标映射
                            0  // 设置虚拟眼镜的深度
                        );
                    }
                }
                lastDetectionTime = currentTime;
            }

            // 继续面部检测
            requestAnimationFrame(detectFace);
        }

        // 渲染函数
        let lastFrameTime = 0;

        function animate() {
            const now = performance.now();
            const elapsed = now - lastFrameTime;
            
            if (elapsed > frameDuration) {
                lastFrameTime = now - (elapsed % frameDuration);
                
                // 只在每一帧中渲染
                renderer.render(scene, camera);

                // 执行面部检测（可设置检测频率）
                detectFace();
            }

            requestAnimationFrame(animate);
        }

        // 监听窗口大小变化
        window.addEventListener('resize', function() {
            renderer.setSize(window.innerWidth, window.innerHeight);
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            videoCanvas.width = window.innerWidth;
            videoCanvas.height = window.innerHeight;
        });

        // 启动初始化
        init();
    </script>
</body>
</html>
