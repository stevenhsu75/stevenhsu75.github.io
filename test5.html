<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>3D Glasses Overlay in 2D Canvas</title>
  <style>
    body { margin: 0; overflow: hidden; }
    canvas { position: absolute; top: 0; left: 0; }
  </style>
</head>
<body>
  <video id="video" width="640" height="480" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  
  <!-- Load Three.js and GLTFLoader -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.132.2/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.132.2/examples/js/loaders/GLTFLoader.js"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d', { willReadFrequently: true });

    // Set canvas size to video size
    canvas.width = video.width;
    canvas.height = video.height;

    // Initialize Three.js scene, camera, and renderer
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(75, canvas.width / canvas.height, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({ canvas: document.createElement('canvas') });
    renderer.setSize(640, 480); // Match the video size
    const renderTarget = new THREE.WebGLRenderTarget(640, 480); // Render to this target

    // Load the glasses 3D model (glasses.glb)
    const loader = new THREE.GLTFLoader();
    let glasses = null;

    loader.load('glasses.glb', (gltf) => {
      glasses = gltf.scene;
      scene.add(glasses);
      
      // Adjust the model position and scale based on the eye positions
      glasses.scale.set(0.1, 0.1, 0.1);  // Example scale for the glasses model
      glasses.position.set(0, 0, -1);   // Adjust the glasses' position in front of the camera
    });

    // Set up video stream (webcam)
    navigator.mediaDevices.getUserMedia({ video: true })
      .then((stream) => {
        video.srcObject = stream;
        video.play();

        video.onloadedmetadata = () => {
          // Start rendering loop after video is ready
          animate();
        };
      })
      .catch((err) => {
        console.error('Error accessing webcam:', err);
      });

    // Eye position and scale (example values, these should come from face detection)
    let eyeX = 200;  // Example x position of the eyes
    let eyeY = 150;  // Example y position of the eyes
    let eyeWidth = 120; // Width of the glasses
    let eyeHeight = 40; // Height of the glasses

    // Function to render the video and overlay 3D glasses as 2D
    function animate() {
      requestAnimationFrame(animate);

      // Draw the current video frame on the canvas
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // If the glasses model is loaded, render it as a 2D texture
      if (glasses) {
        // Render the glasses model to the render target (off-screen)
        renderer.setRenderTarget(renderTarget);
        renderer.render(scene, camera);

        // Reset render target to the default framebuffer (for normal canvas rendering)
        renderer.setRenderTarget(null);

        // Get the texture from the render target
        const texture = renderTarget.texture;

        // Position and scale the glasses (the 2D rendered texture) based on eye positions
    // 确保纹理包含图像（访问纹理的image属性）
        if (texture.image) {
          // Position and scale the glasses (the 2D rendered texture) based on eye positions
          ctx.drawImage(texture.image, eyeX, eyeY, eyeWidth, eyeHeight);
        } else {
          console.error("纹理图像尚未加载或无效！");
        }

     //   ctx.drawImage(texture.image, eyeX, eyeY, eyeWidth, eyeHeight);
      }
    }
  </script>
</body>
</html>
