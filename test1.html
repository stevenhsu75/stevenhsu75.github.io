<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR 試戴眼鏡</title>
    <style>
        body {
            text-align: center;
            background: black;
        }
        video, canvas {
            position: absolute;
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%);
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>

    <!-- 載入 OpenCV.js -->
    <script src="opencv.js"></script>

    <script>
        let video = document.getElementById('video');
        let canvas = document.getElementById('canvas');
        let ctx = canvas.getContext('2d', { willReadFrequently: true });
        let glasses = new Image();
        glasses.src = 'glasses.png';

        let faceCascade, landmarkModel;

        cv['onRuntimeInitialized'] = async () => {
            console.log("✅ OpenCV.js 載入完成！");
            await loadCascade();
            startFaceDetection();
        };

        async function loadCascade() {
            let faceCascadeUrl = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml';
            let landmarkModelUrl = 'https://github.com/php-opencv/php-opencv-examples/blob/master/models/opencv-facemark-lbf/lbfmodel.yaml';

            try {
                // 載入臉部偵測分類器
                let response = await fetch(faceCascadeUrl);
                let buffer = await response.arrayBuffer();
                cv.FS_createDataFile("/", "haarcascade_frontalface_default.xml", new Uint8Array(buffer), true, false, false);
                faceCascade = new cv.CascadeClassifier();
                faceCascade.load("haarcascade_frontalface_default.xml");
                console.log("📂 臉部偵測分類器載入完成");

                // 載入 Landmark (68 點) 模型
                response = await fetch(landmarkModelUrl);
                buffer = await response.arrayBuffer();
                cv.FS_createDataFile("/", "lbfmodel.yaml", new Uint8Array(buffer), true, false, false);
                landmarkModel = new cv.FacemarkLBF();
                landmarkModel.loadModel("lbfmodel.yaml");
                console.log("📂 臉部 Landmark 模型載入完成");

            } catch (error) {
                console.error("❌ 無法載入模型:", error);
            }
        }

        function startFaceDetection() {
            navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                video.srcObject = stream;
                video.onloadeddata = () => {
                    console.log("🎥 相機已就緒！");
                    video.play();
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    setInterval(detectFace, 100);
                };
            }).catch((error) => {
                console.error("❌ 無法啟動相機:", error);
            });
        }

        function detectFace() {
            if (!faceCascade || !landmarkModel) {
                console.warn("⚠️ 臉部偵測或 Landmark 模型尚未載入，跳過偵測");
                return;
            }

            if (video.videoWidth === 0 || video.videoHeight === 0) {
                console.warn("🚨 視訊未準備好，跳過偵測");
                return;
            }

            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            let frame = cv.matFromImageData(imageData);

            let gray = new cv.Mat();
            cv.cvtColor(frame, gray, cv.COLOR_RGBA2GRAY);

            let faces = new cv.RectVector();
            let msize = new cv.Size(30, 30); 
            faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize, new cv.Size());

            if (faces.size() > 0) {
                let face = faces.get(0);
                let landmarks = new cv.MatVector();
                let singleFace = new cv.Mat();
                singleFace.push_back(face);

                // 使用 Landmark 模型偵測 68 點
                if (landmarkModel.fit(gray, singleFace, landmarks)) {
                    let points = landmarks.get(0); 

                    // 取得左眼、右眼座標
                    let leftEye = points.row(36);
                    let rightEye = points.row(45);

                    let eyeCenterX = (leftEye.data32F[0] + rightEye.data32F[0]) / 2;
                    let eyeCenterY = (leftEye.data32F[1] + rightEye.data32F[1]) / 2;

                    let angle = Math.atan2(
                        rightEye.data32F[1] - leftEye.data32F[1],
                        rightEye.data32F[0] - leftEye.data32F[0]
                    ) * (180 / Math.PI);

                    let eyeWidth = face.width * 0.7;
                    let eyeHeight = eyeWidth / 3;

                    console.log(`👓 旋轉角度: ${angle.toFixed(2)}°`);

                    // 旋轉眼鏡
                    drawRotatedImage(glasses, ctx, eyeCenterX, eyeCenterY, eyeWidth, eyeHeight, angle);
                }

                landmarks.delete();
                singleFace.delete();
            } else {
                console.log("❌ 未偵測到臉部！");
            }

            frame.delete();
            gray.delete();
            faces.delete();
        }

        function drawRotatedImage(image, ctx, x, y, width, height, angle) {
            ctx.save();
            ctx.translate(x, y);
            ctx.rotate(angle * Math.PI / 180);
            ctx.drawImage(image, -width / 2, -height / 2, width, height);
            ctx.restore();
        }
    </script>
</body>
</html>
