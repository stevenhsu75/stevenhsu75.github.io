<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR è©¦æˆ´çœ¼é¡</title>
    <style>
        body {
            text-align: center;
            background: black;
        }
        video, canvas {
            position: absolute;
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%);
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>

    <!-- è¼‰å…¥ OpenCV.js -->
    <script src="https://docs.opencv.org/4.5.1/opencv.js"></script>

    <script>
        let video = document.getElementById('video');
        let canvas = document.getElementById('canvas');
        let ctx = canvas.getContext('2d', { willReadFrequently: true });
        let glasses = new Image();
        glasses.src = 'https://stevenhsu75.github.io/glasses.png';

        let faceCascade;

        cv['onRuntimeInitialized'] = async () => {
            console.log("âœ… OpenCV.js è¼‰å…¥å®Œæˆï¼");
            await loadCascade();
            startFaceDetection();
        };

        async function loadCascade() {
            let cascadeFile = 'haarcascade_frontalface_default.xml';
            let cascadeUrl = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml';

            try {
                let response = await fetch(cascadeUrl);
                let buffer = await response.arrayBuffer();
                cv.FS_createDataFile("/", cascadeFile, new Uint8Array(buffer), true, false, false);
                faceCascade = new cv.CascadeClassifier();
                faceCascade.load(cascadeFile);
                console.log("ğŸ“‚ è‡‰éƒ¨åˆ†é¡å™¨è¼‰å…¥å®Œæˆ");
            } catch (error) {
                console.error("âŒ ç„¡æ³•è¼‰å…¥ XML:", error);
            }
        }

        function startFaceDetection() {
            navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                video.srcObject = stream;
                video.onloadeddata = () => {
                    console.log("ğŸ¥ ç›¸æ©Ÿå·²å°±ç·’ï¼");
                    video.play();
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    setInterval(detectFace, 100);
                };
            }).catch((error) => {
                console.error("âŒ ç„¡æ³•å•Ÿå‹•ç›¸æ©Ÿ:", error);
            });
        }

        function detectFace() {
            if (!faceCascade) {
                console.warn("âš ï¸ è‡‰éƒ¨åˆ†é¡å™¨å°šæœªè¼‰å…¥ï¼Œè·³éåµæ¸¬");
                return;
            }

            if (video.videoWidth === 0 || video.videoHeight === 0) {
                console.warn("ğŸš¨ è¦–è¨Šæœªæº–å‚™å¥½ï¼Œè·³éåµæ¸¬");
                return;
            }

            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            let frame = cv.matFromImageData(imageData);

            let gray = new cv.Mat();
            cv.cvtColor(frame, gray, cv.COLOR_RGBA2GRAY);

            let faces = new cv.RectVector();
            let msize = new cv.Size(30, 30); // è¨­å®šæœ€å°è‡‰éƒ¨å°ºå¯¸
            faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize, new cv.Size());

            if (faces.size() > 0) {
                let face = faces.get(0);
                let eyeX = face.x + face.width * 0.15;
                let eyeY = face.y + face.height * 0.3;
                let eyeWidth = face.width * 0.7;
                let eyeHeight = eyeWidth / 3;

                console.log("ğŸ‘“ åµæ¸¬åˆ°è‡‰éƒ¨ï¼Œç¹ªè£½çœ¼é¡ï¼", eyeX, eyeY, eyeWidth, eyeHeight);
                ctx.drawImage(glasses, eyeX, eyeY, eyeWidth, eyeHeight);
            } else {
                console.log("âŒ æœªåµæ¸¬åˆ°è‡‰éƒ¨ï¼");
            }

            frame.delete();
            gray.delete();
            faces.delete();
        }
    </script>
</body>
</html>
