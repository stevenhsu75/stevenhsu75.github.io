<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR è©¦æˆ´çœ¼é¡</title>
    <style>
        body {
            text-align: center;
            background: black;
        }
        video, canvas {
            position: absolute;
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%);
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>

    <!-- è¼‰å…¥ OpenCV.js -->
    <script src="opencv.js"></script>

    <script>
        let video = document.getElementById('video');
        let canvas = document.getElementById('canvas');
        let ctx = canvas.getContext('2d', { willReadFrequently: true });
        let glasses = new Image();
        glasses.src = 'glasses.png';

        let faceCascade, landmarkModel;

        cv['onRuntimeInitialized'] = async () => {
            console.log("âœ… OpenCV.js è¼‰å…¥å®Œæˆï¼");
            await loadCascade();
            startFaceDetection();
        };

        async function loadCascade() {
            let faceCascadeUrl = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml';
            let landmarkModelUrl = 'https://github.com/php-opencv/php-opencv-examples/blob/master/models/opencv-facemark-lbf/lbfmodel.yaml';

            try {
                // è¼‰å…¥è‡‰éƒ¨åµæ¸¬åˆ†é¡å™¨
                let response = await fetch(faceCascadeUrl);
                let buffer = await response.arrayBuffer();
                cv.FS_createDataFile("/", "haarcascade_frontalface_default.xml", new Uint8Array(buffer), true, false, false);
                faceCascade = new cv.CascadeClassifier();
                faceCascade.load("haarcascade_frontalface_default.xml");
                console.log("ğŸ“‚ è‡‰éƒ¨åµæ¸¬åˆ†é¡å™¨è¼‰å…¥å®Œæˆ");

                // è¼‰å…¥ Landmark (68 é») æ¨¡å‹
                response = await fetch(landmarkModelUrl);
                buffer = await response.arrayBuffer();
                cv.FS_createDataFile("/", "lbfmodel.yaml", new Uint8Array(buffer), true, false, false);
                landmarkModel = new cv.FacemarkLBF();
                landmarkModel.loadModel("lbfmodel.yaml");
                console.log("ğŸ“‚ è‡‰éƒ¨ Landmark æ¨¡å‹è¼‰å…¥å®Œæˆ");

            } catch (error) {
                console.error("âŒ ç„¡æ³•è¼‰å…¥æ¨¡å‹:", error);
            }
        }

        function startFaceDetection() {
            navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                video.srcObject = stream;
                video.onloadeddata = () => {
                    console.log("ğŸ¥ ç›¸æ©Ÿå·²å°±ç·’ï¼");
                    video.play();
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    setInterval(detectFace, 100);
                };
            }).catch((error) => {
                console.error("âŒ ç„¡æ³•å•Ÿå‹•ç›¸æ©Ÿ:", error);
            });
        }

        function detectFace() {
            if (!faceCascade || !landmarkModel) {
                console.warn("âš ï¸ è‡‰éƒ¨åµæ¸¬æˆ– Landmark æ¨¡å‹å°šæœªè¼‰å…¥ï¼Œè·³éåµæ¸¬");
                return;
            }

            if (video.videoWidth === 0 || video.videoHeight === 0) {
                console.warn("ğŸš¨ è¦–è¨Šæœªæº–å‚™å¥½ï¼Œè·³éåµæ¸¬");
                return;
            }

            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            let frame = cv.matFromImageData(imageData);

            let gray = new cv.Mat();
            cv.cvtColor(frame, gray, cv.COLOR_RGBA2GRAY);

            let faces = new cv.RectVector();
            let msize = new cv.Size(30, 30); 
            faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize, new cv.Size());

            if (faces.size() > 0) {
                let face = faces.get(0);
                let landmarks = new cv.MatVector();
                let singleFace = new cv.Mat();
                singleFace.push_back(face);

                // ä½¿ç”¨ Landmark æ¨¡å‹åµæ¸¬ 68 é»
                if (landmarkModel.fit(gray, singleFace, landmarks)) {
                    let points = landmarks.get(0); 

                    // å–å¾—å·¦çœ¼ã€å³çœ¼åº§æ¨™
                    let leftEye = points.row(36);
                    let rightEye = points.row(45);

                    let eyeCenterX = (leftEye.data32F[0] + rightEye.data32F[0]) / 2;
                    let eyeCenterY = (leftEye.data32F[1] + rightEye.data32F[1]) / 2;

                    let angle = Math.atan2(
                        rightEye.data32F[1] - leftEye.data32F[1],
                        rightEye.data32F[0] - leftEye.data32F[0]
                    ) * (180 / Math.PI);

                    let eyeWidth = face.width * 0.7;
                    let eyeHeight = eyeWidth / 3;

                    console.log(`ğŸ‘“ æ—‹è½‰è§’åº¦: ${angle.toFixed(2)}Â°`);

                    // æ—‹è½‰çœ¼é¡
                    drawRotatedImage(glasses, ctx, eyeCenterX, eyeCenterY, eyeWidth, eyeHeight, angle);
                }

                landmarks.delete();
                singleFace.delete();
            } else {
                console.log("âŒ æœªåµæ¸¬åˆ°è‡‰éƒ¨ï¼");
            }

            frame.delete();
            gray.delete();
            faces.delete();
        }

        function drawRotatedImage(image, ctx, x, y, width, height, angle) {
            ctx.save();
            ctx.translate(x, y);
            ctx.rotate(angle * Math.PI / 180);
            ctx.drawImage(image, -width / 2, -height / 2, width, height);
            ctx.restore();
        }
    </script>
</body>
</html>
