<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>線上AR換眼鏡</title>

    <!-- 引入 Materialize CSS -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css" rel="stylesheet">
    <!-- 引入 face-api.js -->
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <!-- 引入其他自訂CSS -->
    <style>
        body {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
        }
        #canvas {
            position: absolute;
        }
        #video {
            position: absolute;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        .container {
            z-index: 1;
        }
        .btn {
            z-index: 2;
        }
    </style>
</head>
<body>

    <div class="container">
        <h3 class="center-align">線上AR換眼鏡</h3>
        <button class="btn waves-effect waves-light" id="startBtn">啟動攝像頭</button>
    </div>

    <video id="video" width="640" height="480" autoplay muted></video>
    <canvas id="canvas"></canvas>

    <script>
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        const startBtn = document.getElementById("startBtn");

        // 載入 face-api.js 模型
        async function loadModels() {
            await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
            await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
            console.log("Models Loaded!");
        }

        // 啟動視頻流
        async function startVideo() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: true
            });
            video.srcObject = stream;
        }

        // 開始偵測並疊加眼鏡
        async function detectFace() {
            const detections = await faceapi.detectAllFaces(video).withFaceLandmarks().withFaceDescriptors();
            // 使用 createCanvasFromMedia 並手動設置畫布大小
            canvas.innerHTML = faceapi.createCanvasFromMedia(video);
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const ctx = canvas.getContext('2d');

            // 繪製眼鏡
            detections.forEach(detection => {
                const landmarks = detection.landmarks;
                const leftEye = landmarks.getLeftEye();
                const rightEye = landmarks.getRightEye();

                const eyeWidth = Math.abs(leftEye[0].x - rightEye[0].x) * 2;
                const eyeHeight = Math.abs(leftEye[1].y - rightEye[1].y) * 1.5;

                const x = leftEye[0].x - eyeWidth / 4;
                const y = leftEye[1].y - eyeHeight / 2;

                const img = new Image();
                img.src = "glasses.png"; // 這裡放你的眼鏡圖片
                img.onload = () => {
                    ctx.drawImage(img, x, y, eyeWidth, eyeHeight);
                };
            });
        }

        // 啟動程序
        startBtn.addEventListener("click", async () => {
            await loadModels();
            await startVideo();
            video.addEventListener('play', () => {
                setInterval(detectFace, 100); // 每100ms偵測一次
            });
        });
    </script>
</body>
</html>
